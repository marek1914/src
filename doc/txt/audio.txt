===webrtc===
Webrtc

Android/external/chromium_org/third_party/webrtc/modules/audio_processing
声音处理 audio_processing 库包括：
回声消除(AEC)、AECM(AEC Mobile)、自动增益(AGC)、降噪(NS)、静音检测(VAD)等功能，提升声音质量
音频编码：采用iLIBC/iSAC/G722/PCM16/RED/AVT

===aac===
Pulseaudio

AAC generally achieves better sound quality than MP3 at similar bit rates
MPEG-2 和 MPEG-4中都有aac标准

HE-AAC: High Efficiency Advanced Audio Coding
ISO/IEC 13818-7:1997

LC : Low-Complexity profile

why.ts

PES Packet
AAC Frame
AAC Frame
...
AAC Frame //4-10个，并非固定值
PES Packet

一个PES里有多个AAC帧

pts值：
126000  
146880  20880  232ms
163620  16740  186ms
180359  16739  186ms
194941  14582  162ms
209610  14669  163ms
224190  14580  162ms
238859  14669  163ms
251369  12510  139ms
261810  10441  116ms
272251  10441  116ms
280620  8369   93ms
293220  12600  140ms
309969  16749  186ms

PES包大小在2716上下
每Frame头有duration=23.220ms
每帧取1024采样，每秒帧数 44100/1024 = 43.06640625，每帧时间 1/43.06640625=0.023219955


sidamingbu.ts   MPEG1 Layer II 
一个PES包，包含一个Audio Frame
间隔全部是24ms

planar含义:
YUV分packed和planar格式，左右声道分开存放为planar


int a =(char(*)[9])1234 - (char(*)[9])0;   //值为1234/9  2指针相减得到元素个数


===mp3===
libmad  // MPEG Audio Decoder
libmp3lame // LAME Ain't an Mp3 Encoder
libshine  fixed-point MP3 encoder

低通滤波器用乘法累加器实现

1000次高通滤波

Lsp_Qnt  Comp_LPC 比较耗时

L_add L_sub 去掉溢出检测 44s 不去50s，使用inline速度加快明显，代码量会增加

mp3 高音部分，溢出多

mp3 1152采样/帧，1/44100*1152 = 26.122449ms/帧

ffmpeg -i x.mp3  -c copy x.ts 把mp3转换为ts，用流分析工具看：
每个PES中包含7个Audio Frame(MPEG1 Layer III Joint)
每帧时长：0.026122

huffman.h中的位定义方式  编译器竟不支持

浮点转定点问题
mad.h
/*
 * Fixed-point format: 0xABBBBBBB
 * A == whole part      (sign + 3 bits)
 * B == fractional part (28 bits)
 *
 * Values are signed two's complement, so the effective range is:
 * 0x80000000 to 0x7fffffff
 *       -8.0 to +7.9999999962747097015380859375
 *
 * The smallest representable value is:
 * 0x00000001 == 0.0000000037252902984619140625 (i.e. about 3.725e-9)
 *
 * 28 bits of fractional accuracy represent about
 * 8.6 digits of decimal accuracy.
 *
 * Fixed-point numbers can be added or subtracted as normal
 * integers, but multiplication requires shifting the 64-bit result
 * from 56 fractional bits back to 28 (and rounding.)
 *
 * Changing the definition of MAD_F_FRACBITS is only partially
 * supported, and must be done with care.
 */

注意这里的定点表示方式

位区域定义GreenHill的支持有些特殊
int=4个字节系统上
mad_fixed_t 就是unsigned int 类型

----------
liblame
frontend/lame --nores xx.wav xx.mp3
//320kbps
lame -b 320 why.wav  why.mp3


Lame3.99 压制完美频谱的320KCBR: -b 320 --lowpass -1 (disable lowpass filter,老版本默认disable)
压制信息：Encoding settings : -m j -V 4 -q 3
若无--lowpass -1 ：
Encoding settings : -m j -V 4 -q 3 -lowpass 20.5

gdb:  不优化选项：
--enable-debug=alot,norm   (alot 除了能gdb，还有更多调试信息打印)

b lame_encoder_loop

----
数据存储
why.wav
pcm_s16le
文件：69 0f 37 08 eb 0e 0c 08 46 0f 7f 07 b3 0f 60 08 14 0f 65 08
int Buffer[2][1152]; 中存储数据：
Buffer[0] = 0x0f690000 0x0eeb0000 0x0f460000 0x0fb30000 0x0f140000
Buffer[1] = 0x08370000 0x080c0000 0x077f0000 0x08600000 0x08650000

lame.c:
lame_encode_buffer_int()  // 定点型运算
lame_encode_mp3_frame()

lame --lowpass 8000 why.wav  why1.mp3
再ffplay why1.mp3  会看到频谱很低（窗口的图形 高度有变化）

--verbose  打印信息

没有找到 乘加运算的 滤波器，倒是有FFT ，mp3 用的是MDCT，为啥要fft？难道用于滤波？

psymodel.c   心理声学

=========

立体声原理：
Adobe Audition V3.0  CS6(这个版本更新)
多音轨，音轨对齐，右键拖动
vocal 人声
软件 Audacity  linux版，perfect！

原理：
先做好伴奏音乐，后期将歌手声音等量地混合到左右声道，人声在左右声道的相位相同，幅度一致。根据这个原理，将2个声道相抵消，也就可以把相同相位的人声抵消掉，而一些乐器的声音频谱与相位比较复杂，会保留很多

1 打开mp3 2 分离立体声 3 其中一个invert 4 变为mono   人声变为虚无缥缈效果
心理声学(psychoacoustics)
-------


.wav 文件
头信息包括：采样频率，采样深度，通道数

注意：数据不一定是pcm（虽然多数情况是）
16bit深度采样，2通道，存储格式就是  2B 2B 表示左通道，右通道

用信号发生器 驱动了小喇叭，声音小效果差

hj给我的耳机，用在ipod 3上，插到低出现人声消除的效果，奇怪，不是巧合，说明跟软件起到了相同作用，
与普通耳机相比，根部2段分开而已

pc:  aplay Lemon.wav 可以播放
android 不用标准版alsa-lib/alsa-utils，而是TinyAlsa

alsa-utils：aplay/amixer/arecord

mixer.c pcm.c 生成libtinyalsa.so
基于此库生成3过exe：tinyplay/tinycap/tinymix/tinypcminfo
据相关信息显示，tinyalsa可能被集成到busybox中

何如将ubuntu的mic输入，输入到耳机：

驻极体 :永久带电体

PCM  Pulse-code modulation

mic接法：
http://www.epanorama.net/links/pc_sound.html

electret microphone

驻体话筒，接到microphone，确实能录到声音:
arecord -Dhw:0,0  -d 10 -c 2 -t wav -r 44100 -f "Signed 16 bit Little Endian" xx.wav
必须2通道， 怎么个2通道法，只有一个话筒亚

动圈话筒
驻极体话筒 (电脑 用这种)

电脑话筒 3线

声卡  
浅蓝 line in  用于内录
浅绿 line out 耳机音箱
粉红 mic

耳机插孔有 开关型 无开关型

三芯耳机插头 ，左声道，右声道，地  没啥说的

二芯插头一般用于mic，已经很少见，现在mic也用三芯：
mic输入，mic偏置（bias == pwr?），地 or
mic输入，mic输入，地 or
mic输入，地，地

AC97

mic接口应该是电源，地和信号，3线


我那次电子琴直接输入电脑，用的是line in 还是mic呢？

u10.04 oss驱动: /dev/audio dsp adsp，u11.10后没有了，统一用alsa

alsa声卡节点 /dev/snd/controlC0 
插入usb摄像头后增加：controlC1 和 pcmC1D0c

libasound

内核文档 Documentation/sound/alsa :
ALSA PCM devices to OSS devices mapping (指的是microphone？)
/dev/snd/pcmC0D0 -> /dev/dsp0 (/dev/dsp)

/proc/asound/cards 显示音频设备（android也适用）

/dev/snd (插入usb camera)
116,  6 controlC0
116,  8 controlC1
116,  5 hwC0D2
116,  4 pcmC0D0c (c: capture)
116,  3 pcmC0D0p (p: playback)
116,  2 pcmC0D2p
116,  7 pcmC1D0c
116,  1 seq
116, 33 timer

/proc/asound/devices (与上对应)
  1:        : sequencer
  2: [ 0- 2]: digital audio playback
  3: [ 0- 0]: digital audio playback
  4: [ 0- 0]: digital audio capture
  5: [ 0- 2]: hardware dependent
  6: [ 0]   : control
  7: [ 1- 0]: digital audio capture
  8: [ 1]   : control
 33:        : timer

mstar android:
dev/snd:  (主设备号 14和116)
audio     14,  12 1969-12-31 16:00 adsp                     
audio     14,   4 1969-12-31 16:00 audio                    
audio    116,   0 1969-12-31 16:00 controlC0                
audio     14,   3 1969-12-31 16:00 dsp                      
audio     14,   0 1969-12-31 16:00 mixer                    
audio    116,  24 1969-12-31 16:00 pcmC0D0c                 
audio    116,  16 1969-12-31 16:00 pcmC0D0p                 
audio    116,  25 1969-12-31 16:00 pcmC0D1c                 
audio    116,  17 1969-12-31 16:00 pcmC0D1p                 
audio    116,  33 1969-12-31 16:00 timer 

avformat_open_input


ffplay -f lavfi 'amovie=/dev/snd/pcmC1D0c,showcqt=fps=30:count=5' // alsa usb  不能用
Failed to avformat_open_input '/dev/snd/pcmC1D0c' (libavfilter/Src_movie.c)

ffplay -f lavfi 'amovie=/dev/snd/pcmC1D0c:alsa,showcqt=fps=30:count=5'
ff_alsa_open -> snd_pcm_open(alsa库函数) 时候打印：
ALSA lib pcm.c:2239:(snd_pcm_open_noupdate) Unknown PCM /dev/snd/pcmC1D0c

ffplay -f lavfi 'amovie=hw:1,0,showcqt=fps=30:count=5'

(公司pc)ubuntu -> system Setting -> sound:
输出设备2个：
Headphones (当前面板插入插头)  后面板插入耳机没显示
Analog Output (这个一直存在，不知代表啥)

输入设备：
USB 2.0 Camera(插着usb摄像头的情况下)
Front Microphone (当前面板插入插头) 仅靠插头插入与否检测，就像CA卡
Rear  Microphone (当后面板插入插头) 可以同时支持2个micphone ？
Line In (当后面板line in插入)

aplay -l
**** List of PLAYBACK Hardware Devices ****
card 0: PCH [HDA Intel PCH], device 0: VT1708S Analog [VT1708S Analog]
  Subdevices: 1/1
  Subdevice #0: subdevice #0
card 0: PCH [HDA Intel PCH], device 2: VT1708S Alt Analog [VT1708S Alt Analog]
  Subdevices: 1/1
  Subdevice #0: subdevice #0

arecord -l
**** List of CAPTURE Hardware Devices ****
card 0: PCH [HDA Intel PCH], device 0: VT1708S Analog [VT1708S Analog]
  Subdevices: 1/1
  Subdevice #0: subdevice #0
card 1: Camera [USB 2.0 Camera], device 0: USB Audio [USB Audio] (usb mic ^^)
  Subdevices: 1/1
  Subdevice #0: subdevice #0

arecord -Dhw:1,0 -r8000 -f S16_LE -c 1 1.wav  (参数后面不加空格也行？ ^^)

arecord -Dhw:1,0  -d 20 -c 2 -t wav -r 8000 -f "Signed 16 bit Little Endian" ./xx.wav  提示通道数不对
arecord -Dhw:1,0  -d 20 -c 1 -t wav -r 8000 -f "Signed 16 bit Little Endian" ./xx.wav  ok

若 -r 10000 提示
Warning: rate is not accurate (requested = 10000Hz, got = 11025Hz)

logitech C270： 
arecord -Dhw:1,0 -r 8000 -d 10 -v  -f S16_LE -c 1 1.wav
Warning: rate is not accurate (requested = 8000Hz, got = 16000Hz)
并且-d 10，结果录了5s就退出了

arecord -Dhw:1,0 -r 16000 -d 10 -v  -f S16_LE -c 1 1.wav
这样就录10s

录制电子琴，开始噪音严重，后来把琴音量调低就好很多

内录用的alsa工具 arecored

问题：
usb摄像头的micphone，原始音频采样频率是多少？ 8k？ 11.052k？

PSQM Perceptual Speech Quality Measure

PCM 
声音的pcm与 信号系统的pcm含义不同
https://en.wikipedia.org/wiki/%CE%9C-law_algorithm
http://www.cisco.com/c/en/us/support/docs/voice/h323/8123-waveform-coding.html
http://www.alsa-project.org/alsa-doc/alsa-lib/pcm.html

----------
alsa : http://www.sabi.co.uk/Notes/linuxSoundALSA.html

-----------
哈尔滨
strace arecord -Dhw:1,0  -d 40 -c 1 -t wav -r 16000 -f "Signed 16 bit Little Endian"  xx.wav

open("/dev/snd/controlC1", O_RDONLY|O_CLOEXEC) = 3
fcntl(3, F_SETFD, FD_CLOEXEC)           = 0
ioctl(3, SNDRV_CTL_IOCTL_CARD_INFO or UI_DEV_CREATE, 0x7fffee669840) = 0
close(3)                                = 0

open("/dev/snd/controlC1", O_RDWR|O_CLOEXEC) = 3
fcntl(3, F_SETFD, FD_CLOEXEC)           = 0
ioctl(3, SNDRV_CTL_IOCTL_PVERSION or USBDEVFS_CONTROL, 0x7fffee6699c4) = 0
ioctl(3, SNDRV_CTL_IOCTL_PCM_PREFER_SUBDEVICE, 0x7fffee669a2c) = 0
close(3)                                = 0

open("/dev/snd/pcmC1D0c", O_RDWR|O_NONBLOCK|O_CLOEXEC) = 4
fcntl(4, F_SETFD, FD_CLOEXEC)           = 0
ioctl(4, AGPIOC_ACQUIRE or APM_IOC_STANDBY or SNDRV_PCM_IOCTL_INFO, 0x7fffee6698d0) = 0
fcntl(4, F_GETFL)                       = 0x8802 (flags O_RDWR|O_NONBLOCK|O_LARGEFILE)
ioctl(4, AGPIOC_INFO or SNDRV_PCM_IOCTL_PVERSION, 0x7fffee669820) = 0
ioctl(4, AGPIOC_SETUP or SNDRV_PCM_IOCTL_TTSTAMP, 0x7fffee669824) = 0
ioctl(4, AGPIOC_ACQUIRE or APM_IOC_STANDBY or SNDRV_PCM_IOCTL_INFO, 0x7fffee669e10) = 0
ioctl(4, SNDRV_PCM_IOCTL_HW_REFINE, 0x7fffee667980) = 0
ioctl(4, SNDRV_PCM_IOCTL_SW_PARAMS, 0x7fffee667800) = 0
ioctl(4, SNDRV_PCM_IOCTL_PREPARE, 0x7d0) = 0

open("xx.wav", O_WRONLY|O_CREAT, 0644)  = 3

write(3, "RIFF$\210\23\0WAVE", 12)      = 12
write(3, "fmt \20\0\0\0", 8)            = 8
write(3, "\1\0\1\0\200>\0\0\0}\0\0\2\0\20\0", 16) = 16
write(3, "data\0\210\23\0", 8)          = 8

ioctl(4, SNDRV_PCM_IOCTL_READI_FRAMES, 0x7fffee667d30) = 0
write(3, "\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0"..., 4000) = 4000   // 1/8s
ioctl(4, SNDRV_PCM_IOCTL_READI_FRAMES, 0x7fffee667d30) = 0
write(3, "\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0"..., 4000) = 4000
ioctl(4, SNDRV_PCM_IOCTL_READI_FRAMES, 0x7fffee667d30) = 0
write(3, "\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0"..., 4000) = 4000
...

----
语音遥控器

问题：
如果摄像头和语音遥控同时插这，audiorecoder，如何区分设备？


发送广播事件：
com.funshion.android.intent.action.FUN_TV_RECORD_BUTTON_START
com.funshion.android.intent.action.FUN_TV_RECORD_BUTTON_STOP

2.4G 和 蓝牙的语音遥控器：

语音是怎么发送过来的？

标准驱动？or 特殊驱动

就像usb花柄，一个hid设备，一个语音设备？


2.4G 语音遥控器:

借机会搞明白usb设备系统

busybox lsusb   



/dev/snd/ 多出
audio1
controlC1
dsp1
mixer1
pcmC1D0c


|__ Port 1: Dev 2, If 0, Class=Hub, Driver=hub/8p, 480M
    |__ Port 4: Dev 5, If 0, Class=Audio, Driver=snd-usb-audio, 12M  //为啥2个audio 3个hid interface？
    |__ Port 4: Dev 5, If 1, Class=Audio, Driver=snd-usb-audio, 12M
    |__ Port 4: Dev 5, If 2, Class=Human Interface Device, Driver=usbhid, 12M
    |__ Port 4: Dev 5, If 3, Class=Human Interface Device, Driver=usbhid, 12M
    |__ Port 4: Dev 5, If 4, Class=Human Interface Device, Driver=usbhid, 12M


---------
sys目录下的
bxxx
bmxxx 

//查看lsusb的实现方式：

# strace busybox lsusb

====g711===
adpcm 压缩算法？

octave:

two's complement
bitcmp(0xfe,8)
bitcmp(0xfe00,16)

0xea1f -> 0x29
octave:> bitcmp(0xea1f,16)  //不对，这个仅仅是按位取反
ans =  5600
octave:> lin2mu(-5600)
ans =  41
octave:> dec2hex(ans)
ans = 29

猜想：
16k 采样，间隔去掉数据，变为8k采样，能够播放呀！

There are 2 free scripting languages that are good calculators too:
计算补码：

G711:
 µ-law algorithm  A-law algorithm，都是基于logarithmic的算法

u-law
octave:1> x=(0:0.00001:1);
octave:2> u=255;
octave:3> y=(log(1+u*x))/log(1+u);
octave:4> plot(y,x)
octave:5> plot(x,y)
octave:6> 

=====
ffmpeg 生成 image/audio/10Hz8k.raw
见image/audio/ulaw.jpg, ulaw1.jpg

octave:
x=loadaudio('10Hz8k','raw',16);
y=lin2mu(x);
z=mu2lin(y,16);
plot(x)
hold on
plot(z)

白海涛发过来数据：
输入数据  0x7b06 0x8605 0x8804 0x4803 0xdd01  
输出数据  0xc4   0xc7   0xcb   0xd1   0xdc 
初次验证不正确，不知道是怎么打印的，xuss发现数据反过来就ok了：
octave:dec2hex(lin2mu(0x067b))
octave:ans = C4

===g729===
ITU-T定义

G.723.1 (ffmpeg能 encoder):
30 ms frames
total algorithmic delay is 37.5 ms

Its official name is Dual rate speech coder for multimedia communications transmitting at 5.3 and 6.3 kbit/s.
Note that this is a completely different codec from G.723

There are two bit rates at which G.723.1 can operate:
6.3 kbit/s (using 24 byte frames) using a MPC-MLQ algorithm (MOS 3.9)
5.3 kbit/s (using 20 byte frames) using an ACELP algorithm (MOS 3.62)


G729
frame 10ms(80个采样数据)，点到点时延25ms，8KHz(只能采4k 人声) 采样 16bit，压缩后速率8Kbps
压缩率: 16bit*8k/8K = 16:1


ffmpeg -i input.mp3 -c:a g723_1 -ar 8000 -ac 1 -b:a 6.3K output.wav (为啥是.wav)
需指定 sample rate: 8 kHz, mono audio, bitrate : 6.3 kB/s.

ffplay output.wav //能识别g723

ffplay:
Stream #0:0: Audio: g723_1 (B[0][0][0] / 0x0042), 8000 Hz, mono, s16, 6 kb/s
见 article/RIFF Tags.html  : 0x42 = Microsoft MSG723

ffmpeg -i why.mp4 -c:a aac why.wav
Stream #0:0: Audio: aac (LC) ([255][0][0][0] / 0x00FF), 44100 Hz, stereo, fltp, 420 kb/s
见 article/RIFF Tags.html : 0xff = AAC

WAV文件头：
14H~15H	 格式种类（1表示线性PCM）
16H~17H	 通道数，单声道为1，双声道为2
可见wav是个container，通常保存非压缩pcm，也可保存aac，g723等

libg729 (googlecode, doubango 使用)

---
编译可执行程序：
Makefile.am 添加：
bin_PROGRAMS = core
core_SOURCES = core.c
core_LDADD = 

Pre_Process() 高通滤波，截止频率140Hz，转换前后的pcm，用ffplay播， 窗口最下面似乎有些不同

 * 2nd order high pass filter with cut off frequency at 140 Hz.           *
 * Designed with SPPACK efi command -40 dB att, 0.25 ri.  

G729 preprocessing  section uses a second order pole/zero filter with a cut-off frequency of 140 Hz :
H(z) = (0.46363718-0.927247058.*z.^-1+0.46363718*z.^-2)/(1-1.9059465.*z.^-1+0.9114024*z.^-2);
// 怎么就是140Hz呢？  140Hz 带入不得0.707呀！


分子
0.999970548 +-  0.007674828j  （分子侥幸跟z-b0  一致，因为b0 和b2 相等）
分母
1.04561196 +- 0.062496545j

分子=0.46363718*(1/z-(0.999970548+0.007674828j))*(1/z-(0.999970548-0.007674828j))
分母=0.9114024*(1/z-(1.04561196 +0.062496545j))*(1/z-(1.04561196 -0.062496545j))

//这里不对， zero/pole 点是 (z-a0) 而不是(1/z -a0)

octave:> [z,p,k] = sos2zp([0.46363718 -0.92724705 0.46363718, 1 -1.9059465 0.9114024])
z =

   0.99997 + 0.00767i
   0.99997 - 0.00767i

p =

   0.95297 + 0.05696i
   0.95297 - 0.05696i

k =  0.46364 (k貌似永远等于b0)

得出：
分子= 0.46364*(z-(0.99997 + 0.00767i))*(z-(0.99997 - 0.00767i))
分母=(z-(0.95297 + 0.05696i))*(z-(0.95297 - 0.05696i))


zplane(z,p)  //显示 zero pole点！！ 牛！


octave:1> b=[0.46363718 -0.92724705 0.46363718]
octave:2> a=[1 -1.9059465 0.9114024]
octave:3> freqz(b,a)  //数字滤波器频率响应函数
freqz(b,a,1000,8000)// 横坐标变为Hz
见 octave/g729-high-pass.png  
横坐标是rad/sample 放大取0.035
0.035*8k采样 = 280*pi rad/s    
除以2*pi = 140Hz

这是IIR 《数字信号处理》 p231

Complexity weight  复杂度权重


y[i] = b[0]*x[i]/2 + b[1]*x[i-1]/2 + b[2]*x[i-2]/2  + a[1]*y[i-1]   + a[2]*y[i-2]; 

b[3] = {0.92727435E+00, -0.18544941E+01, 0.92727435E+00};
a[3] = {0.10000000E+01, 0.19059465E+01, -0.91140240E+00};

//浮点转定点(什么原理)
Word16 b140[3] = {1899, -3798, 1899};      /* 1/2 in Q12 */
Word16 a140[3] = {4096, 7807, -3733};      /* Q12 */

Q12 代表4096
Q13 代表8192

最后一个问题,如何确定140Hz (文友用matlab fdatool 确定)

---实验：
经过140Hz高通滤波后的数据，再滤波，数据还会变化吗？

G729AnexA using unpakced 
0x007f ->0 bit 
0x0081->1 bit
packed 到 upakceted

如
21 6B 50 00 9B 33 A0 40 FA 00 7A C2 AC 45

9B : 1001 1011
转换为：
21 6B 50 00 81 00 7F 00 7F 00 81 00 81 00 7F 00 81 00 81 00 

怎么直接packet输出？
转换完的unpacket格式，大小虽没变，但zip压缩到300k，原文件就压不下去还是3.3M左右



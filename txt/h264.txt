TS切片10秒：
I帧必须是IDR帧,间隔精确等于2秒（误差小于10ms）
CBR
PCR/PTS符合ISO/IEC 13818
PTS除正常反转外，需要保持连续
切片以PAT/PMT信息开头紧跟I帧
切片保证PMT/CAT/EMM/ECM等信息完整

slice: 
slice group: 
slice header:
raster scan:

0x6f pps
0x87 sps
0x8f i slice

Elecard Stream Analyzer  Version 2.1.21975(build 91120)

h264没有I帧的概念，只有I Slice， 一帧多个slice，在slice头里面 frame_num 号码相同(IDR此值为0)

SPS: Sequence parameter set
PPS: Picture  parameter set
AUD: Access unit delimiter

seq_parameter_set:
profile_idc u(8)
constraint_set0_flag u(1)
...
constraint_set5_flag u(1)
reserved_zero_2bits /*=0*/ u(2)
level_idc u(8)

Constrained Baseline Profile
CBP, profile_idc=66 with constraint set 1 (constraint_set1_flag=1)

Baseline Profile 
BP, profile_idc=66

注意，这2个profile共用同一个profile_idc 66
CBP和BP的区别，H264.pdf中描述限制项BP+MP=CBP，这并不好理解
看图 H264 profile.jpg，CBP比BP多3向限制：
FMO/ASO/RS (仅BP和XP支持)

Baseline : 
CAVLC entropy coding Yes
CABAC entropy coding No (entropy_coding_mode_flag=0)
颜色只支持YUV420
每通道只支持8bit （9bit-14bit不支持）

PPS 字段 (H264.pdf p79)
entropy_coding_mode_flag=0  可用Golomb or CAVLC
entropy_coding_mode_flag=1  可用CABAC

----
profile描述中
Arbitrary slice order is not allowed (ASO)
Flexible Macroblock Ordering (FMO, 仅BP，XP支持，用处很窄) 这个文档中没有提到呢？  wikipedia有
但貌似跟slice_group_map_type 有关

libx264生成工具 x264，实验一下

libx264提供命令行和API，前者用于GUI如MeGUI，后者用于如FFmpeg

x265 source code is written in C++ and assembly
MPEG-H (ISO/IEC 23008) Part 2 and ITU-T H.265, can support 8K UHD(8192×4320)


h264 可以无损压缩

分析工具：264VISA/Elecard StreamEye Tools/Elecard Stream Analyzer
www.elecard.com/en/download/products.html  各种专业软件以及价格

http://blog.csdn.net/hevc_cjl/article/details/8316653
x264函数说明

3开源编码器：
jm：  h264官方，德国hhi研究所开发，实现264所有特征，结构冗长用于研究不宜实用
x264：实用，摒弃264中对编码性能贡献小但计算复杂度极高的特性
t264：中国开发

jm86
jm90之后主要针对高保真视频

RD曲线

profiles：压缩比
levels ：分辨率

elecard video format analyzer 是个免费工具，winxp安装需要.net 4.0(可以下载到)

h264文档：
7.3.1 NAL unit syntax
NumBytesInRBSP 和 nalUnitHeaderBytes 意思是定义2个变量，并非真正占nal里面的字节

h264对比mpeg2：编码不再基于8x8块，而是在4x4块上进行残差的变换编码（不是16x16吗），dct变换由浮点转为整数，速度快精度高且不溢出

  --disable-mmx            disable MMX optimizations
  --disable-mmxext         disable MMXEXT optimizations
  --disable-sse            disable SSE optimizations
  --disable-sse2           disable SSE2 optimizations
  --disable-sse3           disable SSE3 optimizations
  --disable-ssse3          disable SSSE3 optimizations
  --disable-sse4           disable SSE4 optimizations
  --disable-sse42          disable SSE4.2 optimizations
这些优化肯定是针对编解码器的

luminance ˈlu:mɪnəns 亮度 （流明）
Luma
在视频中，luma描述图像的亮度(黑白)，描述无颜色图像
601 luma 和 709 luma 系数

Luma_Chroma_both.png 仅亮度，仅色度图像对比

Chrominance 'kroʊmɪnəns 色度，描述颜色信息

Hadamard变换，用来计算SATD（一种视频残查信号大小的衡量）
整数运算 避免了一向困扰视频编码的浮点IDCT失谐问题


二次正交变换:为改善大面积平坦图像编码性能，H.264执行二重变换：1)4×4变换；2)对16个4×4变换系数块的直流系数执行4×4 Hadamard变换。


查找264解码库
AVCodec *videoCodec = avcodec_find_decoder(CODEC_ID_H264);
avcodec_open()
开始解码：
libavcodec/utils.c : 
avcodec_decode_video2()
{
	//进入h264.c h264_decode_frame
	ret = avctx->codec->decode(avctx, picture, got_picture_ptr,&tmp); 
}

调用 h264.c 中 decode_nal_units
调用 ff_h264_decode_nal


H264(NAL简介与I帧判断) 
NAL(Network Abstract Layer) 网络抽象层

264系统分为 视频编码层面（VCL）和网络抽象层面（NAL）

会调用
libavcodec/h264dsp.c : ff_h264dsp_init()
调试之：
bit_depth == 8
调用 H264_DSP(8);
执行到这里 gdb p *c 得到：

// ff_h264_idct_add_8_c 这个函数不能直接搜到
// 在./h264idct.h:void ff_h264_idct_add_ ## depth ## _c(uint8_t *dst, int16_t *block, int stride);定义
h264_idct_add = 0x87321d <ff_h264_idct_add_8_c>,  
h264_idct8_add = 0x8736b1 <ff_h264_idct8_add_8_c>, 
h264_idct_dc_add = 0x87441d <ff_h264_idct_dc_add_8_c>, 
h264_idct8_dc_add = 0x8744dd <ff_h264_idct8_dc_add_8_c>, 
h264_idct_add16 = 0x87459d <ff_h264_idct_add16_8_c>, 
h264_idct8_add4 = 0x8747ca <ff_h264_idct8_add4_8_c>, 
h264_idct_add8 = 0x8748eb <ff_h264_idct_add8_8_c>, 
h264_idct_add16intra = 0x8746be <ff_h264_idct_add16intra_8_c>, 
h264_luma_dc_dequant_idct = 0x874ce9 <ff_h264_luma_dc_dequant_idct_8_c>, 
h264_chroma_dc_dequant_idct = 0x87524f <ff_h264_chroma_dc_dequant_idct_8_c>, 
h264_add_pixels8_clear = 0x872014 <ff_h264_add_pixels8_8_c>, 


h264idct.h :

#define H264_IDCT(depth) \
void ff_h264_idct8_add_ ## depth ## _c(uint8_t *dst, int16_t *block, int stride);\
void ff_h264_idct_add_ ## depth ## _c(uint8_t *dst, int16_t *block, int stride);\
void ff_h264_idct8_dc_add_ ## depth ## _c(uint8_t *dst, int16_t *block, int stride);\
void ff_h264_idct_dc_add_ ## depth ## _c(uint8_t *dst, int16_t *block, int stride);\
void ff_h264_idct_add16_ ## depth ## _c(uint8_t *dst, const int *blockoffset, int16_t *block, int stride, const uint8_t nnzc[6*8]);\
void ff_h264_idct_add16intra_ ## depth ## _c(uint8_t *dst, const int *blockoffset, int16_t *block, int stride, const uint8_t nnzc[6*8]);\
void ff_h264_idct8_add4_ ## depth ## _c(uint8_t *dst, const int *blockoffset, int16_t *block, int stride, const uint8_t nnzc[6*8]);\
void ff_h264_idct_add8_422_ ## depth ## _c(uint8_t **dest, const int *blockoffset, int16_t *block, int stride, const uint8_t nnzc[6*8]);\
void ff_h264_idct_add8_ ## depth ## _c(uint8_t **dest, const int *blockoffset, int16_t *block, int stride, const uint8_t nnzc[6*8]);\
void ff_h264_luma_dc_dequant_idct_ ## depth ## _c(int16_t *output, int16_t *input, int qmul);\
void ff_h264_chroma422_dc_dequant_idct_ ## depth ## _c(int16_t *block, int qmul);\
void ff_h264_chroma_dc_dequant_idct_ ## depth ## _c(int16_t *block, int qmul);

//完成函数声明
H264_IDCT( 8)
H264_IDCT( 9)
H264_IDCT(10)
H264_IDCT(12)
H264_IDCT(14)

//函数实现在h264dsp.c:
#define FUNC(a, depth) a ## _ ## depth ## _c

./h264pred.c :
#define FUNCC(a, depth) a ## _ ## depth ## _c

./bit_depth_template.c:
#define FUNCC(a) FUNC2(a, BIT_DEPTH, _c)

./h264idct.c 定义5个./h264idct_template.c中的函数

//不使用mmx/sse的软实现
void FUNCC(ff_h264_idct_add)(uint8_t *_dst, int16_t *_block, int stride) //跟踪时stride==1920 有时== 960 分辨率？
{
这里的实现与 www.docin.com/p-81179124.html 描述的idct一样
x86目录下有 h264_idct.asm : MMX/SSE2-optimized H.264 iDCT
}

一组函数：
ff_h264_idct_add_8_mmx
ff_h264_idct_add_8_c  但是实际走的

入 ff_h264_idct_add_8_c()

#0  ff_h264_idct_add_8_c   (是dct吗？软件实现没用dsp?)
#1  ff_h264_idct_add8_8_c
#2  hl_decode_mb_simple_8
#3  ff_h264_hl_decode_mb
#4  decode_slice
#5  ff_h264_execute_decode_slices
#6  decode_nal_units
#7  h264_decode_frame
#8  avcodec_decode_video2 

有时：
#0  ff_h264_idct_add_8_c
#1  hl_decode_mb_predict_luma
#2  hl_decode_mb_simple_8
#3  ff_h264_hl_decode_mb

h264_mb.c : MPEG4 part10 macroblock decoding


http://ffmpeg.org/doxygen/trunk/dct-test_8c.html  dct测试代码


dct.c 有 dct_calc_II_c()


调用了 libavcodec/x86/h264dsp_init.c ： ff_h264dsp_init_x86()

av_cold void ff_h264dsp_init_x86(H264DSPContext *c, const int bit_depth,
                                 const int chroma_format_idc)
{
#if HAVE_YASM  //没有加速，是因为这个没有满足！

  c->h264_idct_add      = ff_h264_idct_add_8_mmx;
}

struct H264DSPContext{
    /* IDCT */
void (*h264_idct_add)    (uint8_t *dst, int16_t *block, int stride);
void (*h264_idct8_add)   (uint8_t *dst, int16_t *block, int stride);
void (*h264_idct_dc_add) (uint8_t *dst, int16_t *block, int stride);
void (*h264_idct8_dc_add)(uint8_t *dst, int16_t *block, int stride);

void (*h264_idct_add16)            (uint8_t *dst, const int *blockoffset,int16_t *block, int stride, const uint8_t nnzc[15 * 8]);
void (*h264_idct8_add4)            (uint8_t *dst, const int *blockoffset,int16_t *block, int stride, const uint8_t nnzc[15 * 8]);
void (*h264_idct_add16intra)       (uint8_t *dst, const int *blockoffset,int16_t *block, int stride, const uint8_t nnzc[15 * 8]);

void (*h264_idct_add8)             (uint8_t **dst, const int *blockoffset,int16_t *block, int stride,const uint8_t nnzc[15 * 8]);
void (*h264_luma_dc_dequant_idct)  (int16_t *output, int16_t *input, int qmul);
void (*h264_chroma_dc_dequant_idct)(int16_t *block, int qmul);

}

./libavcodec/h264_mb.c:   idct_add    = h->h264dsp.h264_idct_add;

experiment:
从why.mp4中提取一个I帧，然后解码，就能明白h264解码的大部分。

xuss 一段12s 264 mp4视频，中间不能快进，9s以后可以快进，分析只在开始和9s位置有2个i帧，转换成ts格式，可以快进，但9s之前快进花屏

Exp-Golomb codes


I不一定是IDR，非IDR的I帧后B/P可引用此I帧之前的I帧，播放器仅可从一个IDR帧播放

IdrPicFlag=((nal_unit_type == 5)?1:0) //idr nal类型为5

GOP概念不在h264中描述   
一组连续的画面，就是一组连续的I B P  
Group of Pictures   M=3，N=12 表示一组IBP共12个帧，每3个帧出现一个P，即IBBPBBPBBPBBI

non-reference field: nal_ref_idc=0 的field
non-reference frame: nal_ref_idc=0 的frame
non-reference picture ： nal_ref_idc=0 的picture


nal_unit( NumBytesInNALunit ) {
forbidden_zero_bit C
All Descriptor  1bit   固定为0 可以理解为占位用
nal_ref_idc All 2bit
nal_unit_type   5bit



slice_layer_without_partitioning_rbsp( ) {
	slice_header( )
	slice_data( )
	rbsp_slice_trailing_bits( )
}

在家看到一个264视频，I帧被分为很多slice，四大名捕只有1个


理解的里程碑：
I/B/P frame是H262的概念，H264只有I/B/P slice没有相应frame.一帧可含1到多个slice

slice类型0-4和5-9的区别：

1帧分多slice时，0-4后面可以是0-9，若是5-9，后面只能等于它或等于它-5

slice_type 为 0～4 的片可以与异类片共存于一幅图像中，
slice_type 为 5～9 的片只可与同类片共存于一幅图像中，

若某图像第一个片编码为 5 那么该图像后面的片只能 5 或 0；
若第一个片编码为 0，该图像后面的片可编为 0～9 任意一种
一旦后面某片编码为 5，其他片就不能再编码为 5 和 0 之外的类型了，例如： 0，1，5 是错误的）


B帧插越多，P帧的dts和pts的差值越大。
没有B帧，P帧的pts与dts 相等
I帧的pts与dts 永远相等

I B P   B帧在存储的时候在P后面，但是显示时间在P前面


可以没有B帧（why.mp4就没有）在ffmpeg显示运动矢量时，B帧的显示不出来，xuss猜测没有B，把why.mp4转为ts用elecard看真没有
关于“预测”：指的是编码的时候，解码没有预测过程，只是根据存储好的矢量数据解码。
预测有损吗？已经知道量化是有损的，


H264Visa显示mb数据，衔接处有时重复上一mb结尾字节，因为mb是bit流，衔接处字节有1/8可能前几bit属于上一mb，后几bit属于下一mb(xuss niubiful)

在ff_init_cabac_decoder里断点，打印buf，有时第二个字节才能跟H264Visa显示的第一个mb对应上。
不过从下面看：
slice_layer_without_partitioning_rbsp( ) {
	slice_header( )
	slice_data( ) /* all categories of slice_data( ) syntax */
	rbsp_slice_trailing_bits()
}
slice_header( )内部并没有rbsp_slice_trailing_bits()，所以header结束位置不一定字节对齐。

关于slice 分区与不分区：
data partition 只有Extended profile 支持，什么含义尚不明确


slice_layer_without_partitioning_rbsp

slice_data_partition_a_layer_rbsp( ) nal类型2
slice_data_partition_b_layer_rbsp( ) nal类型3
slice_data_partition_c_layer_rbsp( ) nal类型4
我看到的视频都是没有分区的，这里的分区不是1帧分为多个slice，因为我看分为5个slice的
nal类型仍然I帧为5，P帧为1


文档中多次出现 renormalization (重归一化)


pps里面：
num_units_in_tick
time_scale
2个值相除就是帧率


帧率：
30 000 / 1001 Hz = 29.97002997  （这么来的？）



HRD hypothetical ([ˌhaɪpəˈθetɪkl] ) reference decoder




http://yumichan.net

Network Abstraction Layer (NAL) and Video Coding Layer (VCL) are the two main concepts in H.264. A H.264 file consists of a number of NAL units (NALU) and each NALU can be classified as VCL or non-VCL. Video data is processed by the codec and packed into NAL units.

NALU in Packet-Transport Protocol V.S. Byte-Stream Format

There are two ways to pack a NAL unit for different systems, Packet-Transport System and Byte-Stream Format. For Packet-Transport systems like RTP, the transport system protocol frames the coded data into different pieces. Hence, the system can easily identify the boundaries of NAL units and we don’t need to add extra start code, which is a waste of resources. This method is usually used in streaming.

However, in other systems, there is no such protocol to separate NAL units. For example, you want to store a H.264 file and decode it on another computer. The decoder has no idea on how to search the boundaries of the NAL units. So, a three-byte or four-byte start code, 0x000001 or 0x00000001, is added at the beginning of each NAL unit. They are called Byte-Stream Format. Hence, the decoder can now identify the boundaries easily. 

In this series of articles, I will use byte-stream format as an example to introduce H.264. Here is a sample of a H.264 byte-stream. You can see several start codes 0x00000001 here, which means there are several NAL units in this image.


-----
slice_type 
除当前条带的编码类型，所有当前编码图像的其他条带的slice_type

值应与当前条带的slice_type值一样，或者等于当前条带的slice_type 值减5。
那就是当前slice_type=5，除了当前条带的编码类型，所有当前编码图像的其他条带的slice_type，等于0 或5； 
如果当前slice_type=0 当前编码图像的其他slice可为其他任意 slice 类型。

7.4.3 关于slice_type的语义有如下表：
slice_type在5～9时，所有当前编码图像的其他条带的slice_type应与当前条带的slice_type值一样，或等于当前条带的slice_type减5.
slice_type为0～4的片可以与异类片共存于一幅图像中，slice_type 为 5～9 的片只可与同类片共存于一幅图像中。
如果某图像第一个片编码为 slice_type = 5 那么该图像后面的所有片都只能按 slice_type = 5 或 0 进行编码；
若第一个片编码为 0，该图像后面的片可以编码为 0～9 任意一种类型（这里要注意，一旦后面某个片编码为 slice_type = 5，
其他片就不能再编码为5和0之外的类型了，如：第一个片编码为 0，第二个片编码为 1，第三个片编码为 5，这样是错误的）。

片类型的设置问题

JM9.0中，一帧分为多个条带，每个条带的slice_type能设为不同吗？我发现一帧分为多个条带，每个条带的slice_type好像都是一样的。是不是JM9.0只支持这样划分的呢

firstime 发表于 2008-11-10 09:35 AM

可以不一样。JM 只实现了一样的情况。

sunnymov 发表于 2009-8-27 11:16 AM
RE: 关于slice_type

[b] [url=http://bbs.chinavideo.org/redirect.php?goto=findpost&pid=15292&ptid=4526]7#[/url] [i]firstime[/i] [/b]

这么说来slice_type相差5代表的片的类型（5种类型：P、B、I、SP、SI）是相同，slice_type为0-4与5-9的片之间差别在于 是否对后面的片的类型产生影响，
若是0-4则代表不产生影响，而5-9是产生影响，当slice_type为5-9时，当前编码图像后面的片与当前片的类 型是一样的，也即slice_type相差5或者相同

当slice_type为5-9时，当前编码图像后面的片与当前片的类型是一样的

——当前编码图像的所有的片都必须是一样。

“而如果你把第一个片编码为 0，该图像后面的片可以编码为 0～9 任意一种类型（这里要注意，一旦后面某个片编码为 slice_type = 5，
其他片就不能再编码为 5 和 0 之外的类型了，例如：第一个片编码为 0，第二个片编码为 1，第三个片编码为 5，这样是错误的）。”

按照你的意思来理解，例子上之所以错，是因为，第三个为5，其他的不管是前面还是后面就不可以为0和5以外的。 所以准确的讲应该是，
如果第一个为0，其他的就可以为0～4的任意一种，或者是5和0随意，一旦后面有一个为5，前面和后面都不可能出现0和5以外的任何一种类型。
如果有6，其他的也只能是6或者1，就是说5～9类型对全局都有影响。

同样，如果第一个为1，其他的就可以为0～4的任意一种，或者1和6随意。依此类推。是这样吧？

firstime 发表于 2011-1-19 10:59 PM

我要表述的意思就是，在某一图像中可能共存的片只能是下面 6 种情况之一：

1、slice_type = 0～4 的片；
2、slice_type = 0 和 slice_type = 5 的片；
3、slice_type = 1 和 slice_type = 6 的片；
4、slice_type = 2 和 slice_type = 7 的片；
5、slice_type = 3 和 slice_type = 8 的片；
6、slice_type = 4 和 slice_type = 9 的片。

不允许出现除此之外的任何组合。

这么做有什么优点么？能降低码率还是降低复杂度？

H.264 没有 P 图像和 B 图像的概念。而在实际应用中通常一幅图像都采用同一类型的片。
所以这种混合片类型的图像没有统一称呼。H.264 标准中也只是用数字序号来区分他们，见表 7-5；



---cabac---


---cabac demo---
287= 1 00 011111
351= 1 01 011111
415= 1 10 011111
479= 1 11 011111

256 320 384 448 512

why.mp4 第二帧
1 数据 bc 8e 2a fb 74 a1 fe 47 16 db 00 08 eb fe e0
第一次进入get_cabac_inline
解析decode_cabac_mb_skip
s = 21
range=510
low = 0x2f238aa = (0xbc8e2a<<2)+2 = 49428650
新s=17 写回cabac_state[11]
解出bit 0
更新range = 284  low = 2388308

2 开始读P帧的 mb_type
第一次get_cabac_inline
s = 106
range = 284  low = 2388308
新s= 108 写回cabac_state[14]
解出bit 0
更新range = 275 low = 2388308
因为读出bit == 0 第二次 get_cabac_inline
s = 28
range = 275  low=2388308
新s= 30 写回cabac_state[15]
解出bit 0
更新range = 412 low = 4776616   //这里有点问题，解出0 为啥low升高 range也变大了？
因为读出bit == 0 所以执行 mb_type= 3 * get_cabac_noinline(..); 第三次进入：
s=26
range = 412 low= 4776616
新s= 28 写回cabac_state[16]
解出bit 0
range =307 low=4776616

此时解出mb_type = 0;

一路向下执行 partition_count = 1
执行 2185行
if(IS_16X16(mb_type)){  成立进入！
h->list_count == 1
 if (local_ref_count[list] > 1) { //不成立

2204行 DECODE_CABAC_MB_MVD( h, list, 0)  又会进入get_cabac_noinline // 这里解 mvd
ctxbase+((amvd-3)>>(INT_BIT-1))+((amvd-33)>>(INT_BIT-1))+2 这个运算何意？
此时 ctxbase = 40   amvd=0  INT_BIT = 32   -3>>31 == -1   -33>>31 == -1  所以这个运算完还是40
s=0
range = 307  low = 4776616
新s= 2 写回cabac_state[40]
解出bit 0
range =358 low=9553232

因为这次返回0，所以 h264_cabac.c :decode_cabac_mb_mvd() 上来就返回了
紧接着又调用一次decode_cabac_mb_mvd() :
s = 10
range = 358  low = 9553232
新s= 12 写回cabac_state[47]
解出bit 0
range =446 low=19106464

此时的 h->list_count == 1 所以一次就退出

到了2284行， if( IS_INTER( mb_type ) ) {//条件满足
到了2290行，  decode_cabac_mb_cbp_luma  调用4次 get_cabac_noinline ：
ctxIdx = 73 //coded_block_pattern (luma)  73..76
s = 27
range =446 low=19106464
新s= 29 写回cabac_state[73]
解出bit 1
range =341 low=19106464

----
s = 29
range =341 low=19106464
新s= 31 写回cabac_state[73] 
解出bit 1
range = 256 low= 19106464
----
s=31 
range =256 low=19106464
新s= 33 写回cabac_state[73]
解出bit 1
range =380 low=38212928

执行到2291 行

执行到2300 解出cbp = 31 (与h264Visa显示能对上)

执行2303行 

last_significant_coeff_flag[ ]  //cntIdx 339..399

到2343-2369行 解 mb_qp_delta字段 cntIdx 60..63
// decode_cabac_mb_dqp  
if(get_cabac_noinline( &h->cabac, &h->cabac_state[60 + (h->last_qscale_diff != 0)])){

}
到2372行
decode_cabac_luma_residual()

============================
bit	state	low		range
1	0		0		510
0	1		28		480
0	0		24		480
0	2		48		480
0	4		96		506
1	6		96		290
1	4		28		492
0	2		96		432
0	4		192		470
0	6		384		508
0	8		384		303
1	10		256		374
1	8		478		270
0	4		480		464
1	6		448		496
1	4		454		410
1	2		330		374
1	0		50		334
0	1		416		352
0	0		160		352
0	2		320		352
1	4		128		370
0	2		168		316
0	4		336		376
1	6		160		436


M-JPEG帧内压缩，压缩率低于1:20, 帧间压缩（如MPEG2/H.264）可过 1:50. 由于各帧相互独立， M-JPEG的编解码在对运算能力和内存的要求较低。
I/P必选，B可选，实时流通常不要B帧，因B帧需后面数据有延迟

STC:system time clock/counter
PCR:节目时钟参考，负责调整解码器系统时钟频率

PTS 至少700sm传输一次，PCR间隔一般35ms(<100ms)

VBR 动态码率
VFR 动态帧率

SDP(RFC2327)中的SPS和PPS包含初始化264解码器所需参数(profile/level/宽高/deblock滤波器等)以BASE64形式存储。

Nalu 67为sps头 68为pps头


PTS除作为显示时间外，还用于同步

stc 27MHz/300，33bit + 9bit 余数(2^8 < 300 < 2^9，只到0x12C)
前33bit是90k计数器，单位时间 11.111... us，用于产生PTS和DTS

PTS/DTS 33bits 90KHz计数 2^33/90k = 26h30m43s

预测模式：横向，纵向，45度，135度，其他角度共9种

算数编码：0-1之间的小数标示所有信息

---avcc---
Two different flavors of H.264 bitstram.

Annex B format

in this format, each NAL is preceeded by a four byte start code: 0x00 0x00 0x00 0x01
thus in order to know where a NAL start and where it stops, you would need to read each byte of the bitstream, looking for these start codes, which can be a pain if you need to convert between this format and the other format.

AVCC format

This "non Annex B" format is known as AVCC format. in this format, each NAL is precedded by a nal_size field. the size of the field in bytes is in many cases 4, but it is not assumed to be 4, and in fact this is part of the reason why a decoder needs any "extra data", in the first place.

So, Why does a decoder need extradata anyway?

    it needs to know what flavor of the bitstream to expect
    if AVCC format is used, it needs to know what the is the size of the nal_size field, in bytes.
    if the parameters for decoding are not repeated every keyframe, but rather specified only once (such as in a file), it needs those parameters (SPS & PPS in H.264)

How do I get this extradata?

when reading from a file, the extradata is usually part of the headers of the file, you need to extract it from there.

if the extradata is repeated with every key frame, you can try to extract it from the bitstream itself, most of the time it will bundled in the same buffer or packet as the keyframe itself, and preceeding it.

if the bitstream is in annex-b format, you don't need the extradata, because the codec can figure it out itself from the bitstream, at most, you will need to tell the decoder to treat the bitstream as annex-b, which is often achieved by NOT supplying any extradata to begin with.

If the bitstream is in avcc format, you desperately need this extradata, without it the decoder doesn't know how long the nal_size field is, and thus cannot even parse the bitstream.

suppose I have the SPS and PPS information, how do I create the extradata?

For annex-b format, you need:

write(0x00)
write(0x00)
write(0x00)
write(0x01)
for each byte b in SPS
  write(b)

for each PPS p in PPS_array
  write(0x00)
  write(0x00)
  write(0x00)
  write(0x01)
  for each byte b in p
    write(b)

AVCC format extradata is more complicated:

write(0x1);  // version
write(sps[0].data[1]); // profile
write(sps[0].data[2]); // compatibility
write(sps[0].data[3]); // level
write(0xFC | 3); // reserved (6 bits), NULA length size - 1 (2 bits)
write(0xE0 | 1); // reserved (3 bits), num of SPS (5 bits)
write_word(sps[0].size); // 2 bytes for length of SPS

for(int i=0 ; i < sps[0].size ; ++i)
  write(sps[0].data[i]); // data of SPS

write(&b, pps.size());  // num of PPS
for( i=0 ; i < pps.size() ; ++i) {
  write_word(pps[i].size);  // 2 bytes for length of PPS
  for(j=0 ; j < pps[i].size ; ++j)
    write(pps[i].data[j]);  // data of PPS
}


notice how the first byte of the avcc extradata is 1, which makes it obvious it is not a start of an annex-b extradata (which must begin with 0x00)

Notes about .mov files and Quicktime

internally, (at least with version 7.0) quicktime codecs work only with avcc formats and not with annex b format. that means that if you are unlucky enough to have H.264 in annex b format and need to decode it with quicktime codecs (for instance on an iphone) you would need to:

    convert the annex b 0x00 0x00 0x00 0x01 start codes into 4-byte long avcc nal_size fields.
    this requires a loop through the entire buffer, searching for these start codes
    you would need to extract the SPS and PPS NALs, and create an extradata buffer from them in the special format outlined above.

additionally, since .mov container is basically a quicktime container, it is natural that H.264 is stored on .mov files in AVCC format, and thus .mov muxers will need to know how to convert annex-b formatted H.264 buffers intead AVCC formatted H.264 buffers, and also how to convert the extradata buffer into one usable with AVCC format.


---x264---
YUV4MPEG (*.y4m)

.y4m 文件,ffmpeg 里叫 yuv4mpegpipe

.264 -> Raw bytestream  (nal单元流，ES流)

ffmpeg -i why.mp4 why.y4m  输出 yuv4mpegpipe
ffmpeg -i why.mp4 why.yuv  输出 rawvideo

.y4m是有文件头的，
所以：
ffplay why.y4m 可以，而.yuv需要
ffplay -s 1920*1080 why.yuv

y4m格式：
第一帧前：
YUV4MPEG2 W1920 H800 F2397:100 Ip A1:1 C420mpeg2 XYSCSS=420MPEG2\r
每帧前 FRAME\r  6 bytes

Elecard Stream Analyzer 也能分析.264原始流！显示 Elementary Stream
这就是单元流！

thread 怎么用？
x264 [warning]: not compiled with thread support!

--no-8x8dct  这个参数源码没有处理，也就是设置与否都没有任何影响
--no-8x8dct 对应 b_transform_8x8 = 0

观察：I帧没有8x8 8x16 16x8 只有16x16 和 4x4

4x4  8x8 16x16 还没有完全理解，加强一下！

These functions expose the full power of x264's preset-tune-profile system for
easy adjustment of large numbers of internal parameters.

---------------------
"Encoder did not produce proper pts, making some up"


---openh264---
git@github.com:cisco/openh264.git

Q: openh264 Why are many of your functions prefixed with "Wels"?
A: that was the project name for this codec.

openh264 codec ，libx264 encoder

仅支持 Constrained Baseline Profile
YUV 4:2:0 planar input

WelsCreateSVCEncoder()初始化


h264enc -org out.yuv -sw 1920 -sh 1080 -dw 0 1280 -dh 0 720 -frout 0 24 -bf  xxx.264


